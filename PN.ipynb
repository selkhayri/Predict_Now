{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02bb523e",
   "metadata": {},
   "source": [
    "### Load the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93acc70a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import xlsxwriter\n",
    "import pylightxl as xl\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "\n",
    "import pn_config\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483491c1",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f2f7af",
   "metadata": {},
   "source": [
    "### Read the data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "558ccaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# readxl returns a pylightxl database that holds all worksheets and its data\n",
    "db = xl.readxl(fn=f'{pn_config.project_path}/{pn_config.excel_file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6e122a",
   "metadata": {},
   "source": [
    "### Display the column headings of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0aac6cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Time', 'Returns', 'dp', 'dy', 'ep', 'de', 'svar', 'bm', 'ntis', 'tbl', 'lty', 'ltr', 'tms', 'dfy', 'dfr', 'infl']\n"
     ]
    }
   ],
   "source": [
    "print(db.ws(ws=f'{pn_config.sheet_name}').row(row=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33066bc",
   "metadata": {},
   "source": [
    "### Load the rows into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e97287df",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_rows = []\n",
    "\n",
    "for row in db.ws(ws=f'{pn_config.sheet_name}').rows:\n",
    "       file_rows.append(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4d8615",
   "metadata": {},
   "source": [
    "### Load the rows into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3389cdae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Returns</th>\n",
       "      <th>dp</th>\n",
       "      <th>dy</th>\n",
       "      <th>ep</th>\n",
       "      <th>de</th>\n",
       "      <th>svar</th>\n",
       "      <th>bm</th>\n",
       "      <th>ntis</th>\n",
       "      <th>tbl</th>\n",
       "      <th>lty</th>\n",
       "      <th>ltr</th>\n",
       "      <th>tms</th>\n",
       "      <th>dfy</th>\n",
       "      <th>dfr</th>\n",
       "      <th>infl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1945-01</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.041609</td>\n",
       "      <td>-3.027403</td>\n",
       "      <td>-2.662340</td>\n",
       "      <td>-0.379269</td>\n",
       "      <td>0.000924</td>\n",
       "      <td>0.735342</td>\n",
       "      <td>0.016454</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0240</td>\n",
       "      <td>0.0127</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>-0.0051</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1945-02</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.096132</td>\n",
       "      <td>-3.036338</td>\n",
       "      <td>-2.711553</td>\n",
       "      <td>-0.384579</td>\n",
       "      <td>0.000655</td>\n",
       "      <td>0.704489</td>\n",
       "      <td>0.014836</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0236</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>-0.0031</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1945-03</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.043790</td>\n",
       "      <td>-3.091042</td>\n",
       "      <td>-2.653829</td>\n",
       "      <td>-0.389961</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.015963</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0236</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1945-04</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.128109</td>\n",
       "      <td>-3.043790</td>\n",
       "      <td>-2.724389</td>\n",
       "      <td>-0.403720</td>\n",
       "      <td>0.001398</td>\n",
       "      <td>0.715063</td>\n",
       "      <td>0.015086</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0228</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>-0.0142</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1945-05</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.139500</td>\n",
       "      <td>-3.128109</td>\n",
       "      <td>-2.722106</td>\n",
       "      <td>-0.417394</td>\n",
       "      <td>0.000921</td>\n",
       "      <td>0.702911</td>\n",
       "      <td>0.019773</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0226</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>-0.0067</td>\n",
       "      <td>0.005618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Time  Returns        dp        dy        ep        de      svar  \\\n",
       "0  1945-01        1 -3.041609 -3.027403 -2.662340 -0.379269  0.000924   \n",
       "1  1945-02        0 -3.096132 -3.036338 -2.711553 -0.384579  0.000655   \n",
       "2  1945-03        1 -3.043790 -3.091042 -2.653829 -0.389961  0.001887   \n",
       "3  1945-04        1 -3.128109 -3.043790 -2.724389 -0.403720  0.001398   \n",
       "4  1945-05        0 -3.139500 -3.128109 -2.722106 -0.417394  0.000921   \n",
       "\n",
       "         bm      ntis     tbl     lty     ltr     tms     dfy     dfr  \\\n",
       "0  0.735342  0.016454  0.0038  0.0240  0.0127  0.0202  0.0077 -0.0051   \n",
       "1  0.704489  0.014836  0.0038  0.0236  0.0077  0.0198  0.0076 -0.0031   \n",
       "2  0.767883  0.015963  0.0038  0.0236  0.0021  0.0198  0.0076 -0.0003   \n",
       "3  0.715063  0.015086  0.0038  0.0228  0.0160  0.0190  0.0075 -0.0142   \n",
       "4  0.702911  0.019773  0.0038  0.0226  0.0056  0.0188  0.0070 -0.0067   \n",
       "\n",
       "       infl  \n",
       "0  0.000000  \n",
       "1  0.000000  \n",
       "2  0.000000  \n",
       "3  0.000000  \n",
       "4  0.005618  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(file_rows[1:])\n",
    "df.columns = file_rows[0]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a50244e",
   "metadata": {},
   "source": [
    "### Drop dataframe rows with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19be3483",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=0, how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c26d32a",
   "metadata": {},
   "source": [
    "### Check if the classes are unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0860ea41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(383, 516)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df[\"Returns\"] == 0]), len(df[df[\"Returns\"] == 1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51a0ca6",
   "metadata": {},
   "source": [
    "### Create the features database, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d605deb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dp</th>\n",
       "      <th>dy</th>\n",
       "      <th>ep</th>\n",
       "      <th>de</th>\n",
       "      <th>svar</th>\n",
       "      <th>bm</th>\n",
       "      <th>ntis</th>\n",
       "      <th>tbl</th>\n",
       "      <th>lty</th>\n",
       "      <th>ltr</th>\n",
       "      <th>tms</th>\n",
       "      <th>dfy</th>\n",
       "      <th>dfr</th>\n",
       "      <th>infl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.041609</td>\n",
       "      <td>-3.027403</td>\n",
       "      <td>-2.662340</td>\n",
       "      <td>-0.379269</td>\n",
       "      <td>0.000924</td>\n",
       "      <td>0.735342</td>\n",
       "      <td>0.016454</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0240</td>\n",
       "      <td>0.0127</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>-0.0051</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.096132</td>\n",
       "      <td>-3.036338</td>\n",
       "      <td>-2.711553</td>\n",
       "      <td>-0.384579</td>\n",
       "      <td>0.000655</td>\n",
       "      <td>0.704489</td>\n",
       "      <td>0.014836</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0236</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>-0.0031</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.043790</td>\n",
       "      <td>-3.091042</td>\n",
       "      <td>-2.653829</td>\n",
       "      <td>-0.389961</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.015963</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0236</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.128109</td>\n",
       "      <td>-3.043790</td>\n",
       "      <td>-2.724389</td>\n",
       "      <td>-0.403720</td>\n",
       "      <td>0.001398</td>\n",
       "      <td>0.715063</td>\n",
       "      <td>0.015086</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0228</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>-0.0142</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.139500</td>\n",
       "      <td>-3.128109</td>\n",
       "      <td>-2.722106</td>\n",
       "      <td>-0.417394</td>\n",
       "      <td>0.000921</td>\n",
       "      <td>0.702911</td>\n",
       "      <td>0.019773</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0226</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>-0.0067</td>\n",
       "      <td>0.005618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>-3.966309</td>\n",
       "      <td>-3.953266</td>\n",
       "      <td>-3.098391</td>\n",
       "      <td>-0.867918</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>0.233834</td>\n",
       "      <td>-0.012703</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.0206</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.001671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>-3.941330</td>\n",
       "      <td>-3.959587</td>\n",
       "      <td>-3.086025</td>\n",
       "      <td>-0.855304</td>\n",
       "      <td>0.004318</td>\n",
       "      <td>0.237917</td>\n",
       "      <td>-0.010244</td>\n",
       "      <td>0.0195</td>\n",
       "      <td>0.0163</td>\n",
       "      <td>0.0797</td>\n",
       "      <td>-0.0032</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>-0.0059</td>\n",
       "      <td>-0.000051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>-3.951689</td>\n",
       "      <td>-3.934654</td>\n",
       "      <td>-3.108987</td>\n",
       "      <td>-0.842702</td>\n",
       "      <td>0.000605</td>\n",
       "      <td>0.233377</td>\n",
       "      <td>-0.010959</td>\n",
       "      <td>0.0189</td>\n",
       "      <td>0.0170</td>\n",
       "      <td>-0.0192</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>0.0088</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>-3.965984</td>\n",
       "      <td>-3.945758</td>\n",
       "      <td>-3.112869</td>\n",
       "      <td>-0.853115</td>\n",
       "      <td>0.001510</td>\n",
       "      <td>0.232261</td>\n",
       "      <td>-0.013267</td>\n",
       "      <td>0.0165</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>-0.0052</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.002286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>-3.993568</td>\n",
       "      <td>-3.960087</td>\n",
       "      <td>-3.130267</td>\n",
       "      <td>-0.863300</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.223938</td>\n",
       "      <td>-0.007907</td>\n",
       "      <td>0.0154</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>-0.0059</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0088</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>-0.000536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>899 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           dp        dy        ep        de      svar        bm      ntis  \\\n",
       "0   -3.041609 -3.027403 -2.662340 -0.379269  0.000924  0.735342  0.016454   \n",
       "1   -3.096132 -3.036338 -2.711553 -0.384579  0.000655  0.704489  0.014836   \n",
       "2   -3.043790 -3.091042 -2.653829 -0.389961  0.001887  0.767883  0.015963   \n",
       "3   -3.128109 -3.043790 -2.724389 -0.403720  0.001398  0.715063  0.015086   \n",
       "4   -3.139500 -3.128109 -2.722106 -0.417394  0.000921  0.702911  0.019773   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "894 -3.966309 -3.953266 -3.098391 -0.867918  0.000594  0.233834 -0.012703   \n",
       "895 -3.941330 -3.959587 -3.086025 -0.855304  0.004318  0.237917 -0.010244   \n",
       "896 -3.951689 -3.934654 -3.108987 -0.842702  0.000605  0.233377 -0.010959   \n",
       "897 -3.965984 -3.945758 -3.112869 -0.853115  0.001510  0.232261 -0.013267   \n",
       "898 -3.993568 -3.960087 -3.130267 -0.863300  0.000306  0.223938 -0.007907   \n",
       "\n",
       "        tbl     lty     ltr     tms     dfy     dfr      infl  \n",
       "0    0.0038  0.0240  0.0127  0.0202  0.0077 -0.0051  0.000000  \n",
       "1    0.0038  0.0236  0.0077  0.0198  0.0076 -0.0031  0.000000  \n",
       "2    0.0038  0.0236  0.0021  0.0198  0.0076 -0.0003  0.000000  \n",
       "3    0.0038  0.0228  0.0160  0.0190  0.0075 -0.0142  0.000000  \n",
       "4    0.0038  0.0226  0.0056  0.0188  0.0070 -0.0067  0.005618  \n",
       "..      ...     ...     ...     ...     ...     ...       ...  \n",
       "894  0.0210  0.0206  0.0024 -0.0004  0.0099  0.0060  0.001671  \n",
       "895  0.0195  0.0163  0.0797 -0.0032  0.0089 -0.0059 -0.000051  \n",
       "896  0.0189  0.0170 -0.0192 -0.0019  0.0088  0.0002  0.000783  \n",
       "897  0.0165  0.0171 -0.0052  0.0006  0.0091  0.0058  0.002286  \n",
       "898  0.0154  0.0181 -0.0059  0.0027  0.0088  0.0073 -0.000536  \n",
       "\n",
       "[899 rows x 14 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns=[\"Time\",\"Returns\"])\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e20ca70",
   "metadata": {},
   "source": [
    "### Create the target column, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca1fb711",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"Returns\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe0d8f4",
   "metadata": {},
   "source": [
    "### Split the dataset into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13df7303",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c809e2",
   "metadata": {},
   "source": [
    "### Create variables that will hold the information for the best performing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5432e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "global max_score, max_model_name, max_model\n",
    "max_score = 0\n",
    "max_model = None\n",
    "max_model_name = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca6888f",
   "metadata": {},
   "source": [
    "### Create a function that implements the following steps:\n",
    "* that fits a given model to the data; both passed in as arguments \n",
    "* test the training and testing performances of the model\n",
    "* display the confusion matrix for actual vs predicted for the test dataset\n",
    "* if the test performance is better than the current best performance, update the information for best performing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "964184d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(model, model_name, X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    global max_score, max_model_name, max_model \n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    test_score = model.score(X_test, y_test)\n",
    "    print(\"score on test: \" + str(test_score))\n",
    "    print(\"score on train: \"+ str(model.score(X_train, y_train)))\n",
    "    \n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    if test_score > max_score:\n",
    "        max_score = test_score\n",
    "        max_model_name = model_name\n",
    "        max_model = model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386fa402",
   "metadata": {},
   "source": [
    "### Create a logistic regression model, then call train_test to implement the steps explained above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f57d2c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on test: 0.6444444444444445\n",
      "score on train: 0.5761124121779859\n",
      "[[ 1 14]\n",
      " [ 2 28]]\n"
     ]
    }
   ],
   "source": [
    "do_lr = True\n",
    "\n",
    "if do_lr:\n",
    "\n",
    "    lr = LogisticRegression()    \n",
    "    train_test(lr, \"Logistic Regression\", X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939563f5",
   "metadata": {},
   "source": [
    "### Create a Random Forest Classifier model, then call train_test to implement the steps explained above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bb0a8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on test: 0.5555555555555556\n",
      "score on train: 0.9461358313817331\n",
      "[[ 4 11]\n",
      " [ 9 21]]\n"
     ]
    }
   ],
   "source": [
    "do_rf = True\n",
    "\n",
    "if do_rf:\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators=300, criterion=\"gini\", max_depth=10, n_jobs=5) \n",
    "    train_test(rf, \"Random Forest\", X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5c6589",
   "metadata": {},
   "source": [
    "### Create a Support Vector - RBF model, then call train_test to implement the steps explained above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afe5c42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on test: 0.5777777777777777\n",
      "score on train: 0.6768149882903981\n",
      "[[ 7  8]\n",
      " [11 19]]\n"
     ]
    }
   ],
   "source": [
    "do_svc = True\n",
    "\n",
    "if do_svc:\n",
    "    \n",
    "    svc = svm.SVC(kernel=\"rbf\",max_iter=-1,C=10**9, gamma=\"auto\")\n",
    "    train_test(svc, \"Support Vector - RBF\", X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dd9932",
   "metadata": {},
   "source": [
    "### Create a Naive Bayes model, then call train_test to implement the steps explained above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a23ef66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on test: 0.6666666666666666\n",
      "score on train: 0.5690866510538641\n",
      "[[ 0 15]\n",
      " [ 0 30]]\n"
     ]
    }
   ],
   "source": [
    "do_bayes = True\n",
    "\n",
    "if do_bayes:\n",
    "    scaler = MinMaxScaler()\n",
    "    fit = scaler.fit(X_train)\n",
    "    X_train_m = fit.transform(X_train)\n",
    "    X_test_m = fit.transform(X_test)\n",
    "\n",
    "    mnb = MultinomialNB()\n",
    "    train_test(mnb, \"Naive Bayes\", X_train_m, X_test_m, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ee7ea4",
   "metadata": {},
   "source": [
    "### Create a K Nearest Neighbour model, then call train_test to implement the steps explained above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ac8b549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on test: 0.7111111111111111\n",
      "score on train: 0.7330210772833724\n",
      "[[12  3]\n",
      " [10 20]]\n"
     ]
    }
   ],
   "source": [
    "do_knn = True\n",
    "\n",
    "if do_knn:\n",
    "\n",
    "    knn = KNeighborsClassifier(algorithm = 'brute', n_jobs=-1)\n",
    "    train_test(knn, \"K Nearest Neighbour\", X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3badc7c2",
   "metadata": {},
   "source": [
    "### Create a Support Vector - Linear model, then call train_test to implement the steps explained above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9946084f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on test: 0.6666666666666666\n",
      "score on train: 0.5690866510538641\n",
      "[[ 0 15]\n",
      " [ 0 30]]\n"
     ]
    }
   ],
   "source": [
    "do_svm = True\n",
    "\n",
    "if do_svm:\n",
    "    \n",
    "    svm=LinearSVC(C=0.0001)\n",
    "    train_test(svm, \"Support Vector - Linear\", X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fd686e",
   "metadata": {},
   "source": [
    "### Create a Decision Trees model, then call train_test to implement the steps explained above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3cde6187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on test: 0.7555555555555555\n",
      "score on train: 1.0\n",
      "[[ 8  7]\n",
      " [ 4 26]]\n"
     ]
    }
   ],
   "source": [
    "do_dt = True\n",
    "\n",
    "if do_dt:\n",
    "    \n",
    "    clf = DecisionTreeClassifier()\n",
    "    train_test(clf, \"Decision Trees\",X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6f1588",
   "metadata": {},
   "source": [
    "### Create a Bagging Classifier model, then call train_test to implement the steps explained above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3524f722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on test: 0.5111111111111111\n",
      "score on train: 0.9836065573770492\n",
      "[[ 3 12]\n",
      " [10 20]]\n"
     ]
    }
   ],
   "source": [
    "do_bg = True\n",
    "\n",
    "if do_bg:\n",
    "    \n",
    "    bg=BaggingClassifier(DecisionTreeClassifier(),max_samples=0.5,max_features=1.0,n_estimators=1000)\n",
    "    train_test(bg, \"Bagging\", X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52196658",
   "metadata": {},
   "source": [
    "### Create a AdaBoost Classifier model, then call train_test to implement the steps explained above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc9384a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on test: 0.4888888888888889\n",
      "score on train: 0.990632318501171\n",
      "[[ 3 12]\n",
      " [11 19]]\n"
     ]
    }
   ],
   "source": [
    "do_ab = True\n",
    "\n",
    "if do_ab:\n",
    "    \n",
    "    adb = AdaBoostClassifier(DecisionTreeClassifier(min_samples_split=10,max_depth=4),n_estimators=1000,learning_rate=0.6)\n",
    "    train_test(bg, \"AdaBoost\", X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7dbb46",
   "metadata": {},
   "source": [
    "### Create a Tensorflow Neural Network model, then call train_test to implement the steps explained above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26161703",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 10:32:32.832113: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-10-28 10:32:32.832242: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-10-28 10:32:32.832438: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2021-10-28 10:32:32.952911: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-10-28 10:32:32.971808: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299965000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "19/19 [==============================] - 3s 101ms/step - loss: 0.6970 - accuracy: 0.4673 - val_loss: 0.6927 - val_accuracy: 0.5253\n",
      "Epoch 2/150\n",
      "19/19 [==============================] - 1s 77ms/step - loss: 0.6937 - accuracy: 0.5097 - val_loss: 0.6921 - val_accuracy: 0.5253\n",
      "Epoch 3/150\n",
      "19/19 [==============================] - 2s 82ms/step - loss: 0.6905 - accuracy: 0.5502 - val_loss: 0.6919 - val_accuracy: 0.5253\n",
      "Epoch 4/150\n",
      "19/19 [==============================] - 1s 75ms/step - loss: 0.6842 - accuracy: 0.5932 - val_loss: 0.6919 - val_accuracy: 0.5253\n",
      "Epoch 5/150\n",
      "19/19 [==============================] - 2s 79ms/step - loss: 0.6837 - accuracy: 0.6092 - val_loss: 0.6920 - val_accuracy: 0.5253\n",
      "Epoch 6/150\n",
      "19/19 [==============================] - 2s 80ms/step - loss: 0.6898 - accuracy: 0.5521 - val_loss: 0.6921 - val_accuracy: 0.5253\n",
      "Epoch 7/150\n",
      "19/19 [==============================] - 2s 88ms/step - loss: 0.6842 - accuracy: 0.5799 - val_loss: 0.6923 - val_accuracy: 0.5253\n",
      "Epoch 8/150\n",
      "19/19 [==============================] - 1s 78ms/step - loss: 0.6787 - accuracy: 0.5999 - val_loss: 0.6926 - val_accuracy: 0.5253\n",
      "Epoch 9/150\n",
      "19/19 [==============================] - 2s 82ms/step - loss: 0.6800 - accuracy: 0.5970 - val_loss: 0.6928 - val_accuracy: 0.5253\n",
      "Epoch 10/150\n",
      "19/19 [==============================] - 2s 81ms/step - loss: 0.6751 - accuracy: 0.6085 - val_loss: 0.6931 - val_accuracy: 0.5253\n",
      "Epoch 11/150\n",
      "19/19 [==============================] - 2s 81ms/step - loss: 0.6849 - accuracy: 0.5704 - val_loss: 0.6934 - val_accuracy: 0.5253\n",
      "Epoch 12/150\n",
      "19/19 [==============================] - 2s 81ms/step - loss: 0.6883 - accuracy: 0.5573 - val_loss: 0.6937 - val_accuracy: 0.5253\n",
      "Epoch 13/150\n",
      "19/19 [==============================] - 2s 88ms/step - loss: 0.6854 - accuracy: 0.5706 - val_loss: 0.6939 - val_accuracy: 0.5253\n",
      "Epoch 14/150\n",
      "19/19 [==============================] - 2s 87ms/step - loss: 0.6843 - accuracy: 0.5755 - val_loss: 0.6942 - val_accuracy: 0.5253\n",
      "Epoch 15/150\n",
      "19/19 [==============================] - 2s 81ms/step - loss: 0.6761 - accuracy: 0.6011 - val_loss: 0.6943 - val_accuracy: 0.5253\n",
      "Epoch 16/150\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.6750 - accuracy: 0.5982 - val_loss: 0.6946 - val_accuracy: 0.5253\n",
      "Epoch 17/150\n",
      "19/19 [==============================] - 2s 86ms/step - loss: 0.6872 - accuracy: 0.5592 - val_loss: 0.6949 - val_accuracy: 0.5253\n",
      "Epoch 18/150\n",
      "19/19 [==============================] - 1s 77ms/step - loss: 0.6841 - accuracy: 0.5723 - val_loss: 0.6951 - val_accuracy: 0.5253\n",
      "Epoch 19/150\n",
      "19/19 [==============================] - 2s 85ms/step - loss: 0.6838 - accuracy: 0.5640 - val_loss: 0.6955 - val_accuracy: 0.5253\n",
      "Epoch 20/150\n",
      "19/19 [==============================] - 2s 81ms/step - loss: 0.6826 - accuracy: 0.5725 - val_loss: 0.6956 - val_accuracy: 0.5253\n",
      "Epoch 21/150\n",
      "19/19 [==============================] - 2s 81ms/step - loss: 0.6746 - accuracy: 0.5937 - val_loss: 0.6959 - val_accuracy: 0.5253\n",
      "Epoch 22/150\n",
      "19/19 [==============================] - 2s 80ms/step - loss: 0.6747 - accuracy: 0.5836 - val_loss: 0.6961 - val_accuracy: 0.5253\n",
      "Epoch 23/150\n",
      "19/19 [==============================] - 2s 81ms/step - loss: 0.6805 - accuracy: 0.5895 - val_loss: 0.6962 - val_accuracy: 0.5253\n",
      "Epoch 24/150\n",
      "19/19 [==============================] - 1s 78ms/step - loss: 0.6815 - accuracy: 0.5831 - val_loss: 0.6965 - val_accuracy: 0.5253\n",
      "Epoch 25/150\n",
      "19/19 [==============================] - 1s 76ms/step - loss: 0.6756 - accuracy: 0.5981 - val_loss: 0.6967 - val_accuracy: 0.5253\n",
      "Epoch 26/150\n",
      "19/19 [==============================] - 2s 79ms/step - loss: 0.6777 - accuracy: 0.5981 - val_loss: 0.6967 - val_accuracy: 0.5253\n",
      "Epoch 27/150\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.6716 - accuracy: 0.6026 - val_loss: 0.6968 - val_accuracy: 0.5253\n",
      "Epoch 28/150\n",
      "19/19 [==============================] - 2s 79ms/step - loss: 0.6843 - accuracy: 0.5659 - val_loss: 0.6969 - val_accuracy: 0.5253\n",
      "Epoch 29/150\n",
      "19/19 [==============================] - 2s 84ms/step - loss: 0.6794 - accuracy: 0.5802 - val_loss: 0.6971 - val_accuracy: 0.5253\n",
      "Epoch 30/150\n",
      "19/19 [==============================] - 1s 78ms/step - loss: 0.6805 - accuracy: 0.5792 - val_loss: 0.6975 - val_accuracy: 0.5253\n",
      "Epoch 31/150\n",
      "19/19 [==============================] - 2s 87ms/step - loss: 0.6797 - accuracy: 0.5813 - val_loss: 0.6976 - val_accuracy: 0.5253\n",
      "Epoch 32/150\n",
      "19/19 [==============================] - 1s 79ms/step - loss: 0.6660 - accuracy: 0.6267 - val_loss: 0.6977 - val_accuracy: 0.5253\n",
      "Epoch 33/150\n",
      "19/19 [==============================] - 2s 84ms/step - loss: 0.6651 - accuracy: 0.6251 - val_loss: 0.6978 - val_accuracy: 0.5253\n",
      "Epoch 34/150\n",
      "19/19 [==============================] - 2s 84ms/step - loss: 0.6708 - accuracy: 0.6069 - val_loss: 0.6979 - val_accuracy: 0.5253\n",
      "Epoch 35/150\n",
      "19/19 [==============================] - 2s 85ms/step - loss: 0.6729 - accuracy: 0.6005 - val_loss: 0.6979 - val_accuracy: 0.5253\n",
      "Epoch 36/150\n",
      "19/19 [==============================] - 2s 82ms/step - loss: 0.6704 - accuracy: 0.6019 - val_loss: 0.6980 - val_accuracy: 0.5253\n",
      "Epoch 37/150\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.6896 - accuracy: 0.5485 - val_loss: 0.6982 - val_accuracy: 0.5253\n",
      "Epoch 38/150\n",
      "19/19 [==============================] - 2s 84ms/step - loss: 0.6786 - accuracy: 0.5899 - val_loss: 0.6981 - val_accuracy: 0.5253\n",
      "Epoch 39/150\n",
      "19/19 [==============================] - 2s 89ms/step - loss: 0.6722 - accuracy: 0.6008 - val_loss: 0.6980 - val_accuracy: 0.5253\n",
      "Epoch 40/150\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.6761 - accuracy: 0.5962 - val_loss: 0.6980 - val_accuracy: 0.5253\n",
      "Epoch 41/150\n",
      "19/19 [==============================] - 2s 84ms/step - loss: 0.6782 - accuracy: 0.5938 - val_loss: 0.6978 - val_accuracy: 0.5253\n",
      "Epoch 42/150\n",
      "19/19 [==============================] - 2s 85ms/step - loss: 0.6842 - accuracy: 0.5707 - val_loss: 0.6979 - val_accuracy: 0.5253\n",
      "Epoch 43/150\n",
      "19/19 [==============================] - 2s 85ms/step - loss: 0.6828 - accuracy: 0.5767 - val_loss: 0.6978 - val_accuracy: 0.5253\n",
      "Epoch 44/150\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.6816 - accuracy: 0.5829 - val_loss: 0.6977 - val_accuracy: 0.5253\n",
      "Epoch 45/150\n",
      "19/19 [==============================] - 2s 86ms/step - loss: 0.6794 - accuracy: 0.5868 - val_loss: 0.6976 - val_accuracy: 0.5253\n",
      "Epoch 46/150\n",
      "19/19 [==============================] - 2s 85ms/step - loss: 0.6700 - accuracy: 0.6118 - val_loss: 0.6977 - val_accuracy: 0.5253\n",
      "Epoch 47/150\n",
      "19/19 [==============================] - 2s 94ms/step - loss: 0.6804 - accuracy: 0.5813 - val_loss: 0.6977 - val_accuracy: 0.5253\n",
      "Epoch 48/150\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.6829 - accuracy: 0.5714 - val_loss: 0.6975 - val_accuracy: 0.5253\n",
      "Epoch 49/150\n",
      "19/19 [==============================] - 2s 93ms/step - loss: 0.6769 - accuracy: 0.5913 - val_loss: 0.6977 - val_accuracy: 0.5253\n",
      "Epoch 50/150\n",
      "19/19 [==============================] - 2s 88ms/step - loss: 0.6846 - accuracy: 0.5740 - val_loss: 0.6976 - val_accuracy: 0.5253\n",
      "Epoch 51/150\n",
      "19/19 [==============================] - 2s 90ms/step - loss: 0.6778 - accuracy: 0.5884 - val_loss: 0.6976 - val_accuracy: 0.5253\n",
      "Epoch 52/150\n",
      "19/19 [==============================] - 2s 88ms/step - loss: 0.6830 - accuracy: 0.5765 - val_loss: 0.6976 - val_accuracy: 0.5253\n",
      "Epoch 53/150\n",
      "19/19 [==============================] - 2s 89ms/step - loss: 0.6780 - accuracy: 0.5889 - val_loss: 0.6974 - val_accuracy: 0.5253\n",
      "Epoch 54/150\n",
      "19/19 [==============================] - 2s 87ms/step - loss: 0.6782 - accuracy: 0.5827 - val_loss: 0.6977 - val_accuracy: 0.5253\n",
      "Epoch 55/150\n",
      "19/19 [==============================] - 2s 98ms/step - loss: 0.6782 - accuracy: 0.5803 - val_loss: 0.6979 - val_accuracy: 0.5253\n",
      "Epoch 56/150\n",
      "19/19 [==============================] - 2s 107ms/step - loss: 0.6812 - accuracy: 0.5798 - val_loss: 0.6980 - val_accuracy: 0.5253\n",
      "Epoch 57/150\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.6688 - accuracy: 0.6131 - val_loss: 0.6980 - val_accuracy: 0.5253\n",
      "Epoch 58/150\n",
      "19/19 [==============================] - 1s 77ms/step - loss: 0.6779 - accuracy: 0.5824 - val_loss: 0.6982 - val_accuracy: 0.5253\n",
      "Epoch 59/150\n",
      "19/19 [==============================] - 1s 75ms/step - loss: 0.6828 - accuracy: 0.5765 - val_loss: 0.6983 - val_accuracy: 0.5253\n",
      "Epoch 60/150\n",
      "19/19 [==============================] - 1s 76ms/step - loss: 0.6822 - accuracy: 0.5758 - val_loss: 0.6983 - val_accuracy: 0.5253\n",
      "Epoch 61/150\n",
      "19/19 [==============================] - 1s 79ms/step - loss: 0.6745 - accuracy: 0.5980 - val_loss: 0.6982 - val_accuracy: 0.5253\n",
      "Epoch 62/150\n",
      "19/19 [==============================] - 1s 72ms/step - loss: 0.6777 - accuracy: 0.5887 - val_loss: 0.6983 - val_accuracy: 0.5253\n",
      "Epoch 63/150\n",
      "19/19 [==============================] - 1s 76ms/step - loss: 0.6668 - accuracy: 0.6129 - val_loss: 0.6982 - val_accuracy: 0.5253\n",
      "Epoch 64/150\n",
      "19/19 [==============================] - 1s 77ms/step - loss: 0.6754 - accuracy: 0.6012 - val_loss: 0.6979 - val_accuracy: 0.5253\n",
      "Epoch 65/150\n",
      "19/19 [==============================] - 1s 76ms/step - loss: 0.6846 - accuracy: 0.5686 - val_loss: 0.6978 - val_accuracy: 0.5253\n",
      "Epoch 66/150\n",
      "19/19 [==============================] - 2s 79ms/step - loss: 0.6787 - accuracy: 0.5834 - val_loss: 0.6981 - val_accuracy: 0.5253\n",
      "Epoch 67/150\n",
      "19/19 [==============================] - 1s 78ms/step - loss: 0.6817 - accuracy: 0.5736 - val_loss: 0.6980 - val_accuracy: 0.5253\n",
      "Epoch 68/150\n",
      "19/19 [==============================] - 1s 77ms/step - loss: 0.6802 - accuracy: 0.5810 - val_loss: 0.6980 - val_accuracy: 0.5253\n",
      "Epoch 69/150\n",
      "19/19 [==============================] - 2s 99ms/step - loss: 0.6731 - accuracy: 0.5929 - val_loss: 0.6980 - val_accuracy: 0.5253\n",
      "Epoch 70/150\n",
      "19/19 [==============================] - 2s 85ms/step - loss: 0.6779 - accuracy: 0.5812 - val_loss: 0.6983 - val_accuracy: 0.5253\n",
      "Epoch 71/150\n",
      "19/19 [==============================] - 2s 80ms/step - loss: 0.6770 - accuracy: 0.5832 - val_loss: 0.6984 - val_accuracy: 0.5253\n",
      "Epoch 72/150\n",
      "19/19 [==============================] - 2s 88ms/step - loss: 0.6877 - accuracy: 0.5601 - val_loss: 0.6981 - val_accuracy: 0.5253\n",
      "Epoch 73/150\n",
      "19/19 [==============================] - 1s 74ms/step - loss: 0.6646 - accuracy: 0.6247 - val_loss: 0.6982 - val_accuracy: 0.5253\n",
      "Epoch 74/150\n",
      "19/19 [==============================] - 1s 78ms/step - loss: 0.6685 - accuracy: 0.6145 - val_loss: 0.6981 - val_accuracy: 0.5253\n",
      "Epoch 75/150\n",
      "19/19 [==============================] - 1s 75ms/step - loss: 0.6861 - accuracy: 0.5639 - val_loss: 0.6982 - val_accuracy: 0.5253\n",
      "Epoch 76/150\n",
      "19/19 [==============================] - 1s 79ms/step - loss: 0.6787 - accuracy: 0.5868 - val_loss: 0.6981 - val_accuracy: 0.5253\n",
      "Epoch 77/150\n",
      "19/19 [==============================] - 1s 74ms/step - loss: 0.6789 - accuracy: 0.5847 - val_loss: 0.6979 - val_accuracy: 0.5253\n",
      "Epoch 78/150\n",
      "19/19 [==============================] - 1s 75ms/step - loss: 0.6832 - accuracy: 0.5735 - val_loss: 0.6979 - val_accuracy: 0.5253\n",
      "Epoch 79/150\n",
      "19/19 [==============================] - 1s 75ms/step - loss: 0.6788 - accuracy: 0.5813 - val_loss: 0.6981 - val_accuracy: 0.5253\n",
      "Epoch 80/150\n",
      "19/19 [==============================] - 1s 76ms/step - loss: 0.6775 - accuracy: 0.5875 - val_loss: 0.6982 - val_accuracy: 0.5253\n",
      "Epoch 81/150\n",
      "19/19 [==============================] - 1s 80ms/step - loss: 0.6763 - accuracy: 0.5956 - val_loss: 0.6979 - val_accuracy: 0.5253\n",
      "Epoch 82/150\n",
      "19/19 [==============================] - 1s 75ms/step - loss: 0.6722 - accuracy: 0.6088 - val_loss: 0.6979 - val_accuracy: 0.5253\n",
      "Epoch 83/150\n",
      "19/19 [==============================] - 1s 78ms/step - loss: 0.6860 - accuracy: 0.5621 - val_loss: 0.6981 - val_accuracy: 0.5253\n",
      "Epoch 84/150\n",
      "19/19 [==============================] - 1s 78ms/step - loss: 0.6800 - accuracy: 0.5906 - val_loss: 0.6979 - val_accuracy: 0.5253\n",
      "Epoch 85/150\n",
      "19/19 [==============================] - 1s 74ms/step - loss: 0.6842 - accuracy: 0.5751 - val_loss: 0.6978 - val_accuracy: 0.5253\n",
      "Epoch 86/150\n",
      "19/19 [==============================] - 2s 79ms/step - loss: 0.6776 - accuracy: 0.5866 - val_loss: 0.6978 - val_accuracy: 0.5253\n",
      "Epoch 87/150\n",
      "19/19 [==============================] - 2s 79ms/step - loss: 0.6810 - accuracy: 0.5705 - val_loss: 0.6980 - val_accuracy: 0.5253\n",
      "Epoch 88/150\n",
      "19/19 [==============================] - 1s 74ms/step - loss: 0.6774 - accuracy: 0.5878 - val_loss: 0.6980 - val_accuracy: 0.5253\n",
      "Epoch 89/150\n",
      "19/19 [==============================] - 2s 82ms/step - loss: 0.6853 - accuracy: 0.5655 - val_loss: 0.6981 - val_accuracy: 0.5253\n",
      "Epoch 90/150\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.6576 - accuracy: 0.6402 - val_loss: 0.6982 - val_accuracy: 0.5253\n",
      "Epoch 91/150\n",
      "19/19 [==============================] - 1s 75ms/step - loss: 0.6827 - accuracy: 0.5715 - val_loss: 0.6985 - val_accuracy: 0.5253\n",
      "Epoch 92/150\n",
      "19/19 [==============================] - 2s 80ms/step - loss: 0.6801 - accuracy: 0.5828 - val_loss: 0.6985 - val_accuracy: 0.5253\n",
      "Epoch 93/150\n",
      "19/19 [==============================] - 2s 80ms/step - loss: 0.6846 - accuracy: 0.5696 - val_loss: 0.6984 - val_accuracy: 0.5253\n",
      "Epoch 94/150\n",
      "19/19 [==============================] - 1s 79ms/step - loss: 0.6795 - accuracy: 0.5908 - val_loss: 0.6982 - val_accuracy: 0.5253\n",
      "Epoch 95/150\n",
      "19/19 [==============================] - 1s 75ms/step - loss: 0.6829 - accuracy: 0.5723 - val_loss: 0.6984 - val_accuracy: 0.5253\n",
      "Epoch 96/150\n",
      "19/19 [==============================] - 2s 93ms/step - loss: 0.6863 - accuracy: 0.5609 - val_loss: 0.6984 - val_accuracy: 0.5253\n",
      "Epoch 97/150\n",
      "19/19 [==============================] - 1s 77ms/step - loss: 0.6751 - accuracy: 0.5953 - val_loss: 0.6984 - val_accuracy: 0.5253\n",
      "Epoch 98/150\n",
      "19/19 [==============================] - 1s 80ms/step - loss: 0.6729 - accuracy: 0.6010 - val_loss: 0.6982 - val_accuracy: 0.5253\n",
      "Epoch 99/150\n",
      "19/19 [==============================] - 1s 78ms/step - loss: 0.6756 - accuracy: 0.5967 - val_loss: 0.6982 - val_accuracy: 0.5253\n",
      "Epoch 100/150\n",
      "19/19 [==============================] - 1s 79ms/step - loss: 0.6734 - accuracy: 0.6008 - val_loss: 0.6982 - val_accuracy: 0.5253\n",
      "Epoch 101/150\n",
      "19/19 [==============================] - 1s 76ms/step - loss: 0.6807 - accuracy: 0.5819 - val_loss: 0.6982 - val_accuracy: 0.5253\n",
      "Epoch 102/150\n",
      "19/19 [==============================] - 1s 79ms/step - loss: 0.6725 - accuracy: 0.6034 - val_loss: 0.6982 - val_accuracy: 0.5253\n",
      "Epoch 103/150\n",
      "19/19 [==============================] - 1s 78ms/step - loss: 0.6713 - accuracy: 0.6089 - val_loss: 0.6980 - val_accuracy: 0.5253\n",
      "Epoch 104/150\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.6913 - accuracy: 0.5466 - val_loss: 0.6982 - val_accuracy: 0.5253\n",
      "Epoch 105/150\n",
      "19/19 [==============================] - 2s 81ms/step - loss: 0.6694 - accuracy: 0.6095 - val_loss: 0.6981 - val_accuracy: 0.5253\n",
      "Epoch 106/150\n",
      "19/19 [==============================] - 1s 76ms/step - loss: 0.6781 - accuracy: 0.5841 - val_loss: 0.6982 - val_accuracy: 0.5253\n",
      "Epoch 107/150\n",
      "19/19 [==============================] - 1s 72ms/step - loss: 0.6786 - accuracy: 0.5813 - val_loss: 0.6983 - val_accuracy: 0.5253\n",
      "Epoch 108/150\n",
      "19/19 [==============================] - 1s 79ms/step - loss: 0.6876 - accuracy: 0.5658 - val_loss: 0.6984 - val_accuracy: 0.5253\n",
      "Epoch 109/150\n",
      "19/19 [==============================] - 1s 75ms/step - loss: 0.6818 - accuracy: 0.5756 - val_loss: 0.6983 - val_accuracy: 0.5253\n",
      "Epoch 110/150\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.6705 - accuracy: 0.6062 - val_loss: 0.6981 - val_accuracy: 0.5253\n",
      "Epoch 111/150\n",
      "19/19 [==============================] - 1s 78ms/step - loss: 0.6802 - accuracy: 0.5871 - val_loss: 0.6982 - val_accuracy: 0.5253\n",
      "Epoch 112/150\n",
      "19/19 [==============================] - 2s 81ms/step - loss: 0.6843 - accuracy: 0.5690 - val_loss: 0.6980 - val_accuracy: 0.5253\n",
      "Epoch 113/150\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.6713 - accuracy: 0.6078 - val_loss: 0.6981 - val_accuracy: 0.5253\n",
      "Epoch 114/150\n",
      "19/19 [==============================] - 1s 79ms/step - loss: 0.6697 - accuracy: 0.6179 - val_loss: 0.6980 - val_accuracy: 0.5253\n",
      "Epoch 115/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 2s 83ms/step - loss: 0.6725 - accuracy: 0.6042 - val_loss: 0.6979 - val_accuracy: 0.5253\n",
      "Epoch 116/150\n",
      "19/19 [==============================] - 1s 74ms/step - loss: 0.6762 - accuracy: 0.5856 - val_loss: 0.6982 - val_accuracy: 0.5253\n",
      "Epoch 117/150\n",
      "19/19 [==============================] - 2s 81ms/step - loss: 0.6717 - accuracy: 0.6008 - val_loss: 0.6983 - val_accuracy: 0.5253\n",
      "Epoch 118/150\n",
      "19/19 [==============================] - 1s 77ms/step - loss: 0.6706 - accuracy: 0.6120 - val_loss: 0.6982 - val_accuracy: 0.5253\n",
      "Epoch 119/150\n",
      "19/19 [==============================] - 1s 78ms/step - loss: 0.6852 - accuracy: 0.5667 - val_loss: 0.6982 - val_accuracy: 0.5253\n",
      "Epoch 120/150\n",
      "19/19 [==============================] - 1s 78ms/step - loss: 0.6759 - accuracy: 0.5980 - val_loss: 0.6981 - val_accuracy: 0.5253\n",
      "Epoch 121/150\n",
      "19/19 [==============================] - 2s 81ms/step - loss: 0.6782 - accuracy: 0.5855 - val_loss: 0.6980 - val_accuracy: 0.5253\n",
      "Epoch 122/150\n",
      "19/19 [==============================] - 1s 79ms/step - loss: 0.6834 - accuracy: 0.5714 - val_loss: 0.6982 - val_accuracy: 0.5253\n",
      "Epoch 123/150\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.6704 - accuracy: 0.6042 - val_loss: 0.6982 - val_accuracy: 0.5253\n",
      "Epoch 124/150\n",
      "19/19 [==============================] - 2s 81ms/step - loss: 0.6832 - accuracy: 0.5711 - val_loss: 0.6983 - val_accuracy: 0.5253\n",
      "Epoch 125/150\n",
      "19/19 [==============================] - 1s 73ms/step - loss: 0.6780 - accuracy: 0.5822 - val_loss: 0.6983 - val_accuracy: 0.5253\n",
      "Epoch 126/150\n",
      "19/19 [==============================] - 1s 73ms/step - loss: 0.6782 - accuracy: 0.5857 - val_loss: 0.6982 - val_accuracy: 0.5253\n",
      "Epoch 127/150\n",
      "19/19 [==============================] - 1s 76ms/step - loss: 0.6785 - accuracy: 0.5920 - val_loss: 0.6983 - val_accuracy: 0.5253\n",
      "Epoch 128/150\n",
      "19/19 [==============================] - 2s 81ms/step - loss: 0.6738 - accuracy: 0.5967 - val_loss: 0.6984 - val_accuracy: 0.5253\n",
      "Epoch 129/150\n",
      "19/19 [==============================] - 1s 75ms/step - loss: 0.6687 - accuracy: 0.6141 - val_loss: 0.6985 - val_accuracy: 0.5253\n",
      "Epoch 130/150\n",
      "19/19 [==============================] - 2s 79ms/step - loss: 0.6763 - accuracy: 0.5900 - val_loss: 0.6985 - val_accuracy: 0.5253\n",
      "Epoch 131/150\n",
      "19/19 [==============================] - 2s 80ms/step - loss: 0.6759 - accuracy: 0.5930 - val_loss: 0.6985 - val_accuracy: 0.5253\n",
      "Epoch 132/150\n",
      "19/19 [==============================] - 2s 80ms/step - loss: 0.6753 - accuracy: 0.5933 - val_loss: 0.6984 - val_accuracy: 0.5253\n",
      "Epoch 133/150\n",
      "19/19 [==============================] - 1s 79ms/step - loss: 0.6719 - accuracy: 0.5980 - val_loss: 0.6984 - val_accuracy: 0.5253\n",
      "Epoch 134/150\n",
      "19/19 [==============================] - 2s 80ms/step - loss: 0.6731 - accuracy: 0.6015 - val_loss: 0.6986 - val_accuracy: 0.5253\n",
      "Epoch 135/150\n",
      "19/19 [==============================] - 1s 78ms/step - loss: 0.6774 - accuracy: 0.5887 - val_loss: 0.6985 - val_accuracy: 0.5253\n",
      "Epoch 136/150\n",
      "19/19 [==============================] - 1s 79ms/step - loss: 0.6803 - accuracy: 0.5773 - val_loss: 0.6984 - val_accuracy: 0.5253\n",
      "Epoch 137/150\n",
      "19/19 [==============================] - 1s 79ms/step - loss: 0.6770 - accuracy: 0.5931 - val_loss: 0.6983 - val_accuracy: 0.5253\n",
      "Epoch 138/150\n",
      "19/19 [==============================] - 2s 80ms/step - loss: 0.6730 - accuracy: 0.5984 - val_loss: 0.6983 - val_accuracy: 0.5253\n",
      "Epoch 139/150\n",
      "19/19 [==============================] - 2s 80ms/step - loss: 0.6638 - accuracy: 0.6269 - val_loss: 0.6982 - val_accuracy: 0.5253\n",
      "Epoch 140/150\n",
      "19/19 [==============================] - 1s 76ms/step - loss: 0.6899 - accuracy: 0.5603 - val_loss: 0.6981 - val_accuracy: 0.5253\n",
      "Epoch 141/150\n",
      "19/19 [==============================] - 2s 82ms/step - loss: 0.6806 - accuracy: 0.5772 - val_loss: 0.6982 - val_accuracy: 0.5253\n",
      "Epoch 142/150\n",
      "19/19 [==============================] - 1s 75ms/step - loss: 0.6844 - accuracy: 0.5681 - val_loss: 0.6981 - val_accuracy: 0.5253\n",
      "Epoch 143/150\n",
      "19/19 [==============================] - 1s 77ms/step - loss: 0.6737 - accuracy: 0.6022 - val_loss: 0.6980 - val_accuracy: 0.5253\n",
      "Epoch 144/150\n",
      "19/19 [==============================] - 1s 78ms/step - loss: 0.6740 - accuracy: 0.6049 - val_loss: 0.6979 - val_accuracy: 0.5253\n",
      "Epoch 145/150\n",
      "19/19 [==============================] - 1s 77ms/step - loss: 0.6871 - accuracy: 0.5655 - val_loss: 0.6979 - val_accuracy: 0.5253\n",
      "Epoch 146/150\n",
      "19/19 [==============================] - 2s 79ms/step - loss: 0.6864 - accuracy: 0.5609 - val_loss: 0.6979 - val_accuracy: 0.5253\n",
      "Epoch 147/150\n",
      "19/19 [==============================] - 2s 80ms/step - loss: 0.6832 - accuracy: 0.5712 - val_loss: 0.6980 - val_accuracy: 0.5253\n",
      "Epoch 148/150\n",
      "19/19 [==============================] - 2s 81ms/step - loss: 0.6707 - accuracy: 0.6089 - val_loss: 0.6980 - val_accuracy: 0.5253\n",
      "Epoch 149/150\n",
      "19/19 [==============================] - 1s 76ms/step - loss: 0.6606 - accuracy: 0.6303 - val_loss: 0.6980 - val_accuracy: 0.5253\n",
      "Epoch 150/150\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.6759 - accuracy: 0.5952 - val_loss: 0.6979 - val_accuracy: 0.5253\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6519 - accuracy: 0.6667\n",
      "score on test: 0.6666666865348816\n",
      "30\n",
      "45\n",
      "[[ 0 15]\n",
      " [ 0 30]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "nn = True\n",
    "\n",
    "if nn:\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.05)\n",
    "    x_partial_train, x_validation, y_partial_train, y_validation = train_test_split(X_train, y_train, test_size=0.3)\n",
    "    model=models.Sequential()\n",
    "    model.add(layers.Dense(4096,activation='relu',input_shape=(14,)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(layers.Dense(2048,activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(layers.Dense(1024,activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(layers.Dense(512,activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(layers.Dense(256,activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(layers.Dense(128,activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(layers.Dense(64,activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(layers.Dense(32,activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(layers.Dense(16,activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(layers.Dense(1,activation='sigmoid'))\n",
    "\n",
    "    sgd = optimizers.SGD(lr=0.01)\n",
    "\n",
    "    model.compile(optimizer=sgd,loss='binary_crossentropy',metrics=['accuracy'])  # rmsprop\n",
    "    \n",
    "    model.fit(x_partial_train,y_partial_train,epochs=150,validation_data=(x_validation,y_validation))\n",
    "    print(\"score on test: \" + str(model.evaluate(X_test,y_test)[1]))\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = [0 if y < 0.5 else 1 for y in y_pred]\n",
    "    \n",
    "    print(sum(y_pred == y_test))\n",
    "    print(len(y_test))\n",
    "    \n",
    "    y_test.reset_index(drop=True,inplace=True)\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    test_score = sum(y_pred == y_test)/len(y_test)\n",
    "    \n",
    "    if test_score > max_score:\n",
    "        print(\"NN\")\n",
    "        max_score = test_score\n",
    "        max_model_name = \"Neural Network\"\n",
    "        max_model = model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0aaa80",
   "metadata": {},
   "source": [
    "### Save the mode so it can be retrieved by the prediction service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "138d72f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"predict_now.sav\"\n",
    "\n",
    "with open(filename,'wb') as f:\n",
    "    pickle.dump(max_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "52722681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Decision Trees', 0.7555555555555555)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_model_name, max_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93acc70a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import xlsxwriter\n",
    "import pylightxl as xl\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "\n",
    "import config\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "558ccaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# readxl returns a pylightxl database that holds all worksheets and its data\n",
    "db = xl.readxl(fn=f'{config.project_path}/SPX_train_0.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0aac6cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Time', 'Returns', 'dp', 'dy', 'ep', 'de', 'svar', 'bm', 'ntis', 'tbl', 'lty', 'ltr', 'tms', 'dfy', 'dfr', 'infl']\n"
     ]
    }
   ],
   "source": [
    "print(db.ws(ws='Sheet1').row(row=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e97287df",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_rows = []\n",
    "\n",
    "for row in db.ws(ws='Sheet1').rows:\n",
    "       file_rows.append(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3389cdae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Returns</th>\n",
       "      <th>dp</th>\n",
       "      <th>dy</th>\n",
       "      <th>ep</th>\n",
       "      <th>de</th>\n",
       "      <th>svar</th>\n",
       "      <th>bm</th>\n",
       "      <th>ntis</th>\n",
       "      <th>tbl</th>\n",
       "      <th>lty</th>\n",
       "      <th>ltr</th>\n",
       "      <th>tms</th>\n",
       "      <th>dfy</th>\n",
       "      <th>dfr</th>\n",
       "      <th>infl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1945-01</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.041609</td>\n",
       "      <td>-3.027403</td>\n",
       "      <td>-2.662340</td>\n",
       "      <td>-0.379269</td>\n",
       "      <td>0.000924</td>\n",
       "      <td>0.735342</td>\n",
       "      <td>0.016454</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0240</td>\n",
       "      <td>0.0127</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>-0.0051</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1945-02</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.096132</td>\n",
       "      <td>-3.036338</td>\n",
       "      <td>-2.711553</td>\n",
       "      <td>-0.384579</td>\n",
       "      <td>0.000655</td>\n",
       "      <td>0.704489</td>\n",
       "      <td>0.014836</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0236</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>-0.0031</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1945-03</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.043790</td>\n",
       "      <td>-3.091042</td>\n",
       "      <td>-2.653829</td>\n",
       "      <td>-0.389961</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.015963</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0236</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1945-04</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.128109</td>\n",
       "      <td>-3.043790</td>\n",
       "      <td>-2.724389</td>\n",
       "      <td>-0.403720</td>\n",
       "      <td>0.001398</td>\n",
       "      <td>0.715063</td>\n",
       "      <td>0.015086</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0228</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>-0.0142</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1945-05</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.139500</td>\n",
       "      <td>-3.128109</td>\n",
       "      <td>-2.722106</td>\n",
       "      <td>-0.417394</td>\n",
       "      <td>0.000921</td>\n",
       "      <td>0.702911</td>\n",
       "      <td>0.019773</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0226</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>-0.0067</td>\n",
       "      <td>0.005618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Time  Returns        dp        dy        ep        de      svar  \\\n",
       "0  1945-01        1 -3.041609 -3.027403 -2.662340 -0.379269  0.000924   \n",
       "1  1945-02        0 -3.096132 -3.036338 -2.711553 -0.384579  0.000655   \n",
       "2  1945-03        1 -3.043790 -3.091042 -2.653829 -0.389961  0.001887   \n",
       "3  1945-04        1 -3.128109 -3.043790 -2.724389 -0.403720  0.001398   \n",
       "4  1945-05        0 -3.139500 -3.128109 -2.722106 -0.417394  0.000921   \n",
       "\n",
       "         bm      ntis     tbl     lty     ltr     tms     dfy     dfr  \\\n",
       "0  0.735342  0.016454  0.0038  0.0240  0.0127  0.0202  0.0077 -0.0051   \n",
       "1  0.704489  0.014836  0.0038  0.0236  0.0077  0.0198  0.0076 -0.0031   \n",
       "2  0.767883  0.015963  0.0038  0.0236  0.0021  0.0198  0.0076 -0.0003   \n",
       "3  0.715063  0.015086  0.0038  0.0228  0.0160  0.0190  0.0075 -0.0142   \n",
       "4  0.702911  0.019773  0.0038  0.0226  0.0056  0.0188  0.0070 -0.0067   \n",
       "\n",
       "       infl  \n",
       "0  0.000000  \n",
       "1  0.000000  \n",
       "2  0.000000  \n",
       "3  0.000000  \n",
       "4  0.005618  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(file_rows[1:])\n",
    "df.columns = file_rows[0]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0860ea41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(383, 516)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df[\"Returns\"] == 0]), len(df[df[\"Returns\"] == 1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d605deb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dp</th>\n",
       "      <th>dy</th>\n",
       "      <th>ep</th>\n",
       "      <th>de</th>\n",
       "      <th>svar</th>\n",
       "      <th>bm</th>\n",
       "      <th>ntis</th>\n",
       "      <th>tbl</th>\n",
       "      <th>lty</th>\n",
       "      <th>ltr</th>\n",
       "      <th>tms</th>\n",
       "      <th>dfy</th>\n",
       "      <th>dfr</th>\n",
       "      <th>infl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.041609</td>\n",
       "      <td>-3.027403</td>\n",
       "      <td>-2.662340</td>\n",
       "      <td>-0.379269</td>\n",
       "      <td>0.000924</td>\n",
       "      <td>0.735342</td>\n",
       "      <td>0.016454</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0240</td>\n",
       "      <td>0.0127</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>-0.0051</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.096132</td>\n",
       "      <td>-3.036338</td>\n",
       "      <td>-2.711553</td>\n",
       "      <td>-0.384579</td>\n",
       "      <td>0.000655</td>\n",
       "      <td>0.704489</td>\n",
       "      <td>0.014836</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0236</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>-0.0031</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.043790</td>\n",
       "      <td>-3.091042</td>\n",
       "      <td>-2.653829</td>\n",
       "      <td>-0.389961</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.015963</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0236</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.128109</td>\n",
       "      <td>-3.043790</td>\n",
       "      <td>-2.724389</td>\n",
       "      <td>-0.403720</td>\n",
       "      <td>0.001398</td>\n",
       "      <td>0.715063</td>\n",
       "      <td>0.015086</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0228</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>-0.0142</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.139500</td>\n",
       "      <td>-3.128109</td>\n",
       "      <td>-2.722106</td>\n",
       "      <td>-0.417394</td>\n",
       "      <td>0.000921</td>\n",
       "      <td>0.702911</td>\n",
       "      <td>0.019773</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0226</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>-0.0067</td>\n",
       "      <td>0.005618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>-3.966309</td>\n",
       "      <td>-3.953266</td>\n",
       "      <td>-3.098391</td>\n",
       "      <td>-0.867918</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>0.233834</td>\n",
       "      <td>-0.012703</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.0206</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.001671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>-3.941330</td>\n",
       "      <td>-3.959587</td>\n",
       "      <td>-3.086025</td>\n",
       "      <td>-0.855304</td>\n",
       "      <td>0.004318</td>\n",
       "      <td>0.237917</td>\n",
       "      <td>-0.010244</td>\n",
       "      <td>0.0195</td>\n",
       "      <td>0.0163</td>\n",
       "      <td>0.0797</td>\n",
       "      <td>-0.0032</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>-0.0059</td>\n",
       "      <td>-0.000051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>-3.951689</td>\n",
       "      <td>-3.934654</td>\n",
       "      <td>-3.108987</td>\n",
       "      <td>-0.842702</td>\n",
       "      <td>0.000605</td>\n",
       "      <td>0.233377</td>\n",
       "      <td>-0.010959</td>\n",
       "      <td>0.0189</td>\n",
       "      <td>0.0170</td>\n",
       "      <td>-0.0192</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>0.0088</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>-3.965984</td>\n",
       "      <td>-3.945758</td>\n",
       "      <td>-3.112869</td>\n",
       "      <td>-0.853115</td>\n",
       "      <td>0.001510</td>\n",
       "      <td>0.232261</td>\n",
       "      <td>-0.013267</td>\n",
       "      <td>0.0165</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>-0.0052</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.002286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>-3.993568</td>\n",
       "      <td>-3.960087</td>\n",
       "      <td>-3.130267</td>\n",
       "      <td>-0.863300</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.223938</td>\n",
       "      <td>-0.007907</td>\n",
       "      <td>0.0154</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>-0.0059</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0088</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>-0.000536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>899 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           dp        dy        ep        de      svar        bm      ntis  \\\n",
       "0   -3.041609 -3.027403 -2.662340 -0.379269  0.000924  0.735342  0.016454   \n",
       "1   -3.096132 -3.036338 -2.711553 -0.384579  0.000655  0.704489  0.014836   \n",
       "2   -3.043790 -3.091042 -2.653829 -0.389961  0.001887  0.767883  0.015963   \n",
       "3   -3.128109 -3.043790 -2.724389 -0.403720  0.001398  0.715063  0.015086   \n",
       "4   -3.139500 -3.128109 -2.722106 -0.417394  0.000921  0.702911  0.019773   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "894 -3.966309 -3.953266 -3.098391 -0.867918  0.000594  0.233834 -0.012703   \n",
       "895 -3.941330 -3.959587 -3.086025 -0.855304  0.004318  0.237917 -0.010244   \n",
       "896 -3.951689 -3.934654 -3.108987 -0.842702  0.000605  0.233377 -0.010959   \n",
       "897 -3.965984 -3.945758 -3.112869 -0.853115  0.001510  0.232261 -0.013267   \n",
       "898 -3.993568 -3.960087 -3.130267 -0.863300  0.000306  0.223938 -0.007907   \n",
       "\n",
       "        tbl     lty     ltr     tms     dfy     dfr      infl  \n",
       "0    0.0038  0.0240  0.0127  0.0202  0.0077 -0.0051  0.000000  \n",
       "1    0.0038  0.0236  0.0077  0.0198  0.0076 -0.0031  0.000000  \n",
       "2    0.0038  0.0236  0.0021  0.0198  0.0076 -0.0003  0.000000  \n",
       "3    0.0038  0.0228  0.0160  0.0190  0.0075 -0.0142  0.000000  \n",
       "4    0.0038  0.0226  0.0056  0.0188  0.0070 -0.0067  0.005618  \n",
       "..      ...     ...     ...     ...     ...     ...       ...  \n",
       "894  0.0210  0.0206  0.0024 -0.0004  0.0099  0.0060  0.001671  \n",
       "895  0.0195  0.0163  0.0797 -0.0032  0.0089 -0.0059 -0.000051  \n",
       "896  0.0189  0.0170 -0.0192 -0.0019  0.0088  0.0002  0.000783  \n",
       "897  0.0165  0.0171 -0.0052  0.0006  0.0091  0.0058  0.002286  \n",
       "898  0.0154  0.0181 -0.0059  0.0027  0.0088  0.0073 -0.000536  \n",
       "\n",
       "[899 rows x 14 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns=[\"Time\",\"Returns\"])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca1fb711",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"Returns\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13df7303",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5432e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "global max_score, max_model_name, max_model\n",
    "max_score = 0\n",
    "max_model = None\n",
    "max_model_name = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "964184d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(model, model_name, X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    global max_score, max_model_name, max_model \n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    test_score = model.score(X_test, y_test)\n",
    "    print(\"score on test: \" + str(test_score))\n",
    "    print(\"score on train: \"+ str(model.score(X_train, y_train)))\n",
    "    \n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    if test_score > max_score:\n",
    "        max_score = test_score\n",
    "        max_model_name = model_name\n",
    "        max_model = model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f57d2c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on test: 0.6666666666666666\n",
      "score on train: 0.572599531615925\n",
      "[[ 1 12]\n",
      " [ 3 29]]\n"
     ]
    }
   ],
   "source": [
    "do_lr = True\n",
    "\n",
    "if do_lr:\n",
    "\n",
    "    lr = LogisticRegression()    \n",
    "    train_test(lr, \"Logistic Regression\", X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bb0a8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on test: 0.5555555555555556\n",
      "score on train: 0.9578454332552693\n",
      "[[ 2 11]\n",
      " [ 9 23]]\n"
     ]
    }
   ],
   "source": [
    "do_rf = True\n",
    "\n",
    "if do_rf:\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators=300, criterion=\"gini\", max_depth=10, n_jobs=5) \n",
    "    train_test(rf, \"Random Forest\", X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afe5c42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on test: 0.6888888888888889\n",
      "score on train: 0.6651053864168618\n",
      "[[ 7  6]\n",
      " [ 8 24]]\n"
     ]
    }
   ],
   "source": [
    "do_svc = True\n",
    "\n",
    "if do_svc:\n",
    "    \n",
    "    svc = svm.SVC(kernel=\"rbf\",max_iter=-1,C=10**9, gamma=\"auto\")\n",
    "    train_test(svc, \"Support Vector - RBF\", X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a23ef66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on test: 0.7111111111111111\n",
      "score on train: 0.5667447306791569\n",
      "[[ 0 13]\n",
      " [ 0 32]]\n"
     ]
    }
   ],
   "source": [
    "do_bayes = True\n",
    "\n",
    "if do_bayes:\n",
    "    scaler = MinMaxScaler()\n",
    "    fit = scaler.fit(X_train)\n",
    "    X_train_m = fit.transform(X_train)\n",
    "    X_test_m = fit.transform(X_test)\n",
    "\n",
    "    mnb = MultinomialNB()\n",
    "    train_test(mnb, \"Naive Bayes\", X_train_m, X_test_m, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ac8b549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on test: 0.5777777777777777\n",
      "score on train: 0.7377049180327869\n",
      "[[ 7  6]\n",
      " [13 19]]\n"
     ]
    }
   ],
   "source": [
    "do_knn = True\n",
    "\n",
    "if do_knn:\n",
    "\n",
    "    knn = KNeighborsClassifier(algorithm = 'brute', n_jobs=-1)\n",
    "    train_test(knn, \"K Nearest Neighbour\", X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9946084f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on test: 0.7111111111111111\n",
      "score on train: 0.5667447306791569\n",
      "[[ 0 13]\n",
      " [ 0 32]]\n"
     ]
    }
   ],
   "source": [
    "do_svm = True\n",
    "\n",
    "if do_svm:\n",
    "    \n",
    "    svm=LinearSVC(C=0.0001)\n",
    "    train_test(svm, \"Support Vector - Linear\", X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3cde6187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on test: 0.4888888888888889\n",
      "score on train: 1.0\n",
      "[[ 3 10]\n",
      " [13 19]]\n"
     ]
    }
   ],
   "source": [
    "do_dt = True\n",
    "\n",
    "if do_dt:\n",
    "    \n",
    "    clf = DecisionTreeClassifier()\n",
    "    train_test(clf, \"Decision Trees\",X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3524f722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on test: 0.5777777777777777\n",
      "score on train: 0.9918032786885246\n",
      "[[ 5  8]\n",
      " [11 21]]\n"
     ]
    }
   ],
   "source": [
    "do_bg = True\n",
    "\n",
    "if do_bg:\n",
    "    \n",
    "    bg=BaggingClassifier(DecisionTreeClassifier(),max_samples=0.5,max_features=1.0,n_estimators=1000)\n",
    "    train_test(bg, \"Bagging\", X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc9384a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on test: 0.6\n",
      "score on train: 0.990632318501171\n",
      "[[ 4  9]\n",
      " [ 9 23]]\n"
     ]
    }
   ],
   "source": [
    "do_ab = True\n",
    "\n",
    "if do_ab:\n",
    "    \n",
    "    adb = AdaBoostClassifier(DecisionTreeClassifier(min_samples_split=10,max_depth=4),n_estimators=1000,learning_rate=0.6)\n",
    "    train_test(bg, \"AdaBoost\", X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26161703",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-27 20:52:23.386274: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-10-27 20:52:23.386404: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-10-27 20:52:23.386646: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2021-10-27 20:52:23.508108: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-10-27 20:52:23.526949: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299965000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "19/19 [==============================] - 3s 100ms/step - loss: 0.6971 - accuracy: 0.4493 - val_loss: 0.6929 - val_accuracy: 0.5175\n",
      "Epoch 2/150\n",
      "19/19 [==============================] - 1s 74ms/step - loss: 0.6949 - accuracy: 0.4429 - val_loss: 0.6911 - val_accuracy: 0.5759\n",
      "Epoch 3/150\n",
      "19/19 [==============================] - 2s 98ms/step - loss: 0.6918 - accuracy: 0.5747 - val_loss: 0.6899 - val_accuracy: 0.5759\n",
      "Epoch 4/150\n",
      "19/19 [==============================] - 1s 76ms/step - loss: 0.6910 - accuracy: 0.5573 - val_loss: 0.6889 - val_accuracy: 0.5759\n",
      "Epoch 5/150\n",
      "19/19 [==============================] - 2s 78ms/step - loss: 0.6904 - accuracy: 0.5640 - val_loss: 0.6882 - val_accuracy: 0.5759\n",
      "Epoch 6/150\n",
      "19/19 [==============================] - 1s 76ms/step - loss: 0.6882 - accuracy: 0.5791 - val_loss: 0.6873 - val_accuracy: 0.5759\n",
      "Epoch 7/150\n",
      "19/19 [==============================] - 1s 75ms/step - loss: 0.6865 - accuracy: 0.5934 - val_loss: 0.6867 - val_accuracy: 0.5759\n",
      "Epoch 8/150\n",
      "19/19 [==============================] - 1s 75ms/step - loss: 0.6911 - accuracy: 0.5405 - val_loss: 0.6861 - val_accuracy: 0.5759\n",
      "Epoch 9/150\n",
      "19/19 [==============================] - 1s 76ms/step - loss: 0.6896 - accuracy: 0.5493 - val_loss: 0.6855 - val_accuracy: 0.5759\n",
      "Epoch 10/150\n",
      "19/19 [==============================] - 1s 74ms/step - loss: 0.6913 - accuracy: 0.5376 - val_loss: 0.6850 - val_accuracy: 0.5759\n",
      "Epoch 11/150\n",
      "19/19 [==============================] - 1s 75ms/step - loss: 0.6818 - accuracy: 0.6012 - val_loss: 0.6846 - val_accuracy: 0.5759\n",
      "Epoch 12/150\n",
      "19/19 [==============================] - 2s 79ms/step - loss: 0.6857 - accuracy: 0.5754 - val_loss: 0.6843 - val_accuracy: 0.5759\n",
      "Epoch 13/150\n",
      "19/19 [==============================] - 1s 75ms/step - loss: 0.6817 - accuracy: 0.5995 - val_loss: 0.6841 - val_accuracy: 0.5759\n",
      "Epoch 14/150\n",
      "19/19 [==============================] - 1s 74ms/step - loss: 0.6871 - accuracy: 0.5643 - val_loss: 0.6838 - val_accuracy: 0.5759\n",
      "Epoch 15/150\n",
      "19/19 [==============================] - 2s 88ms/step - loss: 0.6853 - accuracy: 0.5623 - val_loss: 0.6834 - val_accuracy: 0.5759\n",
      "Epoch 16/150\n",
      "19/19 [==============================] - 2s 84ms/step - loss: 0.6863 - accuracy: 0.5650 - val_loss: 0.6833 - val_accuracy: 0.5759\n",
      "Epoch 17/150\n",
      "19/19 [==============================] - 2s 86ms/step - loss: 0.6849 - accuracy: 0.5627 - val_loss: 0.6830 - val_accuracy: 0.5759\n",
      "Epoch 18/150\n",
      "19/19 [==============================] - 1s 79ms/step - loss: 0.6763 - accuracy: 0.6107 - val_loss: 0.6829 - val_accuracy: 0.5759\n",
      "Epoch 19/150\n",
      "19/19 [==============================] - 1s 78ms/step - loss: 0.6816 - accuracy: 0.5854 - val_loss: 0.6828 - val_accuracy: 0.5759\n",
      "Epoch 20/150\n",
      "19/19 [==============================] - 2s 79ms/step - loss: 0.6732 - accuracy: 0.6243 - val_loss: 0.6826 - val_accuracy: 0.5759\n",
      "Epoch 21/150\n",
      "19/19 [==============================] - 2s 92ms/step - loss: 0.6798 - accuracy: 0.5889 - val_loss: 0.6825 - val_accuracy: 0.5759\n",
      "Epoch 22/150\n",
      "19/19 [==============================] - 1s 79ms/step - loss: 0.6806 - accuracy: 0.5810 - val_loss: 0.6824 - val_accuracy: 0.5759\n",
      "Epoch 23/150\n",
      "19/19 [==============================] - 1s 75ms/step - loss: 0.6808 - accuracy: 0.5843 - val_loss: 0.6823 - val_accuracy: 0.5759\n",
      "Epoch 24/150\n",
      "19/19 [==============================] - 2s 84ms/step - loss: 0.6876 - accuracy: 0.5559 - val_loss: 0.6823 - val_accuracy: 0.5759\n",
      "Epoch 25/150\n",
      "19/19 [==============================] - 2s 88ms/step - loss: 0.6862 - accuracy: 0.5599 - val_loss: 0.6822 - val_accuracy: 0.5759\n",
      "Epoch 26/150\n",
      "19/19 [==============================] - 2s 81ms/step - loss: 0.6811 - accuracy: 0.5814 - val_loss: 0.6821 - val_accuracy: 0.5759\n",
      "Epoch 27/150\n",
      "19/19 [==============================] - 2s 82ms/step - loss: 0.6799 - accuracy: 0.5804 - val_loss: 0.6821 - val_accuracy: 0.5759\n",
      "Epoch 28/150\n",
      "19/19 [==============================] - 2s 81ms/step - loss: 0.6900 - accuracy: 0.5449 - val_loss: 0.6820 - val_accuracy: 0.5759\n",
      "Epoch 29/150\n",
      "19/19 [==============================] - 2s 90ms/step - loss: 0.6831 - accuracy: 0.5674 - val_loss: 0.6820 - val_accuracy: 0.5759\n",
      "Epoch 30/150\n",
      "19/19 [==============================] - 2s 86ms/step - loss: 0.6922 - accuracy: 0.5378 - val_loss: 0.6820 - val_accuracy: 0.5759\n",
      "Epoch 31/150\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.6831 - accuracy: 0.5719 - val_loss: 0.6820 - val_accuracy: 0.5759\n",
      "Epoch 32/150\n",
      "19/19 [==============================] - 2s 80ms/step - loss: 0.6952 - accuracy: 0.5254 - val_loss: 0.6819 - val_accuracy: 0.5759\n",
      "Epoch 33/150\n",
      "19/19 [==============================] - 1s 76ms/step - loss: 0.6849 - accuracy: 0.5627 - val_loss: 0.6819 - val_accuracy: 0.5759\n",
      "Epoch 34/150\n",
      "19/19 [==============================] - 2s 89ms/step - loss: 0.6910 - accuracy: 0.5384 - val_loss: 0.6819 - val_accuracy: 0.5759\n",
      "Epoch 35/150\n",
      "19/19 [==============================] - 2s 86ms/step - loss: 0.6828 - accuracy: 0.5696 - val_loss: 0.6819 - val_accuracy: 0.5759\n",
      "Epoch 36/150\n",
      "19/19 [==============================] - 2s 82ms/step - loss: 0.6805 - accuracy: 0.5819 - val_loss: 0.6819 - val_accuracy: 0.5759\n",
      "Epoch 37/150\n",
      "19/19 [==============================] - 2s 84ms/step - loss: 0.6838 - accuracy: 0.5675 - val_loss: 0.6819 - val_accuracy: 0.5759\n",
      "Epoch 38/150\n",
      "19/19 [==============================] - 1s 78ms/step - loss: 0.6827 - accuracy: 0.5785 - val_loss: 0.6819 - val_accuracy: 0.5759\n",
      "Epoch 39/150\n",
      "19/19 [==============================] - 1s 78ms/step - loss: 0.6822 - accuracy: 0.5804 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 40/150\n",
      "19/19 [==============================] - 1s 77ms/step - loss: 0.6787 - accuracy: 0.5877 - val_loss: 0.6819 - val_accuracy: 0.5759\n",
      "Epoch 41/150\n",
      "19/19 [==============================] - 2s 92ms/step - loss: 0.6838 - accuracy: 0.5719 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 42/150\n",
      "19/19 [==============================] - 2s 94ms/step - loss: 0.6779 - accuracy: 0.5900 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 43/150\n",
      "19/19 [==============================] - 2s 89ms/step - loss: 0.6866 - accuracy: 0.5556 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 44/150\n",
      "19/19 [==============================] - 1s 78ms/step - loss: 0.6891 - accuracy: 0.5528 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 45/150\n",
      "19/19 [==============================] - 2s 80ms/step - loss: 0.6873 - accuracy: 0.5545 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 46/150\n",
      "19/19 [==============================] - 1s 77ms/step - loss: 0.6800 - accuracy: 0.5836 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 47/150\n",
      "19/19 [==============================] - 2s 85ms/step - loss: 0.6788 - accuracy: 0.5848 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 48/150\n",
      "19/19 [==============================] - 2s 85ms/step - loss: 0.6884 - accuracy: 0.5553 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 49/150\n",
      "19/19 [==============================] - 2s 81ms/step - loss: 0.6817 - accuracy: 0.5760 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 50/150\n",
      "19/19 [==============================] - 1s 79ms/step - loss: 0.6818 - accuracy: 0.5750 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 51/150\n",
      "19/19 [==============================] - 2s 87ms/step - loss: 0.6817 - accuracy: 0.5802 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 52/150\n",
      "19/19 [==============================] - 1s 80ms/step - loss: 0.6819 - accuracy: 0.5709 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 53/150\n",
      "19/19 [==============================] - 2s 80ms/step - loss: 0.6777 - accuracy: 0.5937 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 54/150\n",
      "19/19 [==============================] - 2s 90ms/step - loss: 0.6865 - accuracy: 0.5570 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 55/150\n",
      "19/19 [==============================] - 2s 82ms/step - loss: 0.6756 - accuracy: 0.5970 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 56/150\n",
      "19/19 [==============================] - 2s 82ms/step - loss: 0.6885 - accuracy: 0.5528 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 57/150\n",
      "19/19 [==============================] - 2s 80ms/step - loss: 0.6833 - accuracy: 0.5693 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 58/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 79ms/step - loss: 0.6972 - accuracy: 0.5237 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 59/150\n",
      "19/19 [==============================] - 1s 77ms/step - loss: 0.6753 - accuracy: 0.5994 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 60/150\n",
      "19/19 [==============================] - 1s 75ms/step - loss: 0.6820 - accuracy: 0.5728 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 61/150\n",
      "19/19 [==============================] - 1s 77ms/step - loss: 0.6899 - accuracy: 0.5521 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 62/150\n",
      "19/19 [==============================] - 1s 76ms/step - loss: 0.6679 - accuracy: 0.6266 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 63/150\n",
      "19/19 [==============================] - 1s 76ms/step - loss: 0.6839 - accuracy: 0.5690 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 64/150\n",
      "19/19 [==============================] - 1s 73ms/step - loss: 0.6890 - accuracy: 0.5541 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 65/150\n",
      "19/19 [==============================] - 1s 73ms/step - loss: 0.6829 - accuracy: 0.5652 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 66/150\n",
      "19/19 [==============================] - 1s 78ms/step - loss: 0.6771 - accuracy: 0.5898 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 67/150\n",
      "19/19 [==============================] - 2s 86ms/step - loss: 0.6791 - accuracy: 0.5826 - val_loss: 0.6817 - val_accuracy: 0.5759\n",
      "Epoch 68/150\n",
      "19/19 [==============================] - 2s 86ms/step - loss: 0.6777 - accuracy: 0.5962 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 69/150\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.6850 - accuracy: 0.5655 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 70/150\n",
      "19/19 [==============================] - 1s 77ms/step - loss: 0.6808 - accuracy: 0.5759 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 71/150\n",
      "19/19 [==============================] - 1s 78ms/step - loss: 0.6794 - accuracy: 0.5872 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 72/150\n",
      "19/19 [==============================] - 2s 86ms/step - loss: 0.6795 - accuracy: 0.5831 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 73/150\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.6884 - accuracy: 0.5571 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 74/150\n",
      "19/19 [==============================] - 1s 74ms/step - loss: 0.6781 - accuracy: 0.5868 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 75/150\n",
      "19/19 [==============================] - 1s 77ms/step - loss: 0.6878 - accuracy: 0.5567 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 76/150\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.6799 - accuracy: 0.5805 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 77/150\n",
      "19/19 [==============================] - 2s 86ms/step - loss: 0.6826 - accuracy: 0.5720 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 78/150\n",
      "19/19 [==============================] - 1s 74ms/step - loss: 0.6895 - accuracy: 0.5492 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 79/150\n",
      "19/19 [==============================] - 2s 80ms/step - loss: 0.6854 - accuracy: 0.5604 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 80/150\n",
      "19/19 [==============================] - 2s 90ms/step - loss: 0.6841 - accuracy: 0.5666 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 81/150\n",
      "19/19 [==============================] - 2s 89ms/step - loss: 0.6844 - accuracy: 0.5645 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 82/150\n",
      "19/19 [==============================] - 2s 89ms/step - loss: 0.6870 - accuracy: 0.5554 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 83/150\n",
      "19/19 [==============================] - 2s 85ms/step - loss: 0.6784 - accuracy: 0.5880 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 84/150\n",
      "19/19 [==============================] - 2s 82ms/step - loss: 0.6819 - accuracy: 0.5767 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 85/150\n",
      "19/19 [==============================] - 1s 78ms/step - loss: 0.6919 - accuracy: 0.5428 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 86/150\n",
      "19/19 [==============================] - 1s 78ms/step - loss: 0.6809 - accuracy: 0.5791 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 87/150\n",
      "19/19 [==============================] - 2s 82ms/step - loss: 0.6821 - accuracy: 0.5738 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 88/150\n",
      "19/19 [==============================] - 1s 76ms/step - loss: 0.6793 - accuracy: 0.5842 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 89/150\n",
      "19/19 [==============================] - 1s 77ms/step - loss: 0.6842 - accuracy: 0.5625 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 90/150\n",
      "19/19 [==============================] - 2s 85ms/step - loss: 0.6858 - accuracy: 0.5575 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 91/150\n",
      "19/19 [==============================] - 2s 81ms/step - loss: 0.6857 - accuracy: 0.5622 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 92/150\n",
      "19/19 [==============================] - 1s 75ms/step - loss: 0.6811 - accuracy: 0.5770 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 93/150\n",
      "19/19 [==============================] - 2s 81ms/step - loss: 0.6773 - accuracy: 0.5899 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 94/150\n",
      "19/19 [==============================] - 2s 92ms/step - loss: 0.6767 - accuracy: 0.5957 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 95/150\n",
      "19/19 [==============================] - 2s 85ms/step - loss: 0.6788 - accuracy: 0.5844 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 96/150\n",
      "19/19 [==============================] - 2s 84ms/step - loss: 0.6865 - accuracy: 0.5567 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 97/150\n",
      "19/19 [==============================] - 2s 80ms/step - loss: 0.6847 - accuracy: 0.5655 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 98/150\n",
      "19/19 [==============================] - 1s 77ms/step - loss: 0.6797 - accuracy: 0.5817 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 99/150\n",
      "19/19 [==============================] - 2s 92ms/step - loss: 0.6881 - accuracy: 0.5591 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 100/150\n",
      "19/19 [==============================] - 2s 95ms/step - loss: 0.6814 - accuracy: 0.5757 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 101/150\n",
      "19/19 [==============================] - 2s 80ms/step - loss: 0.6789 - accuracy: 0.5853 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 102/150\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.6752 - accuracy: 0.5988 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 103/150\n",
      "19/19 [==============================] - 2s 91ms/step - loss: 0.6822 - accuracy: 0.5741 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 104/150\n",
      "19/19 [==============================] - 2s 86ms/step - loss: 0.6831 - accuracy: 0.5683 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 105/150\n",
      "19/19 [==============================] - 1s 76ms/step - loss: 0.6815 - accuracy: 0.5763 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 106/150\n",
      "19/19 [==============================] - 1s 76ms/step - loss: 0.6800 - accuracy: 0.5812 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 107/150\n",
      "19/19 [==============================] - 2s 91ms/step - loss: 0.6871 - accuracy: 0.5553 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 108/150\n",
      "19/19 [==============================] - 2s 85ms/step - loss: 0.6813 - accuracy: 0.5782 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 109/150\n",
      "19/19 [==============================] - 2s 94ms/step - loss: 0.6811 - accuracy: 0.5759 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 110/150\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.6773 - accuracy: 0.5900 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 111/150\n",
      "19/19 [==============================] - 2s 89ms/step - loss: 0.6871 - accuracy: 0.5576 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 112/150\n",
      "19/19 [==============================] - 1s 78ms/step - loss: 0.6821 - accuracy: 0.5715 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 113/150\n",
      "19/19 [==============================] - 2s 82ms/step - loss: 0.6784 - accuracy: 0.5925 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 114/150\n",
      "19/19 [==============================] - 1s 78ms/step - loss: 0.6809 - accuracy: 0.5782 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 115/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 77ms/step - loss: 0.6789 - accuracy: 0.5833 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 116/150\n",
      "19/19 [==============================] - 1s 73ms/step - loss: 0.6837 - accuracy: 0.5724 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 117/150\n",
      "19/19 [==============================] - 1s 80ms/step - loss: 0.6856 - accuracy: 0.5596 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 118/150\n",
      "19/19 [==============================] - 1s 76ms/step - loss: 0.6807 - accuracy: 0.5795 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 119/150\n",
      "19/19 [==============================] - 2s 86ms/step - loss: 0.6803 - accuracy: 0.5793 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 120/150\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.6826 - accuracy: 0.5764 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 121/150\n",
      "19/19 [==============================] - 1s 78ms/step - loss: 0.6761 - accuracy: 0.5938 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 122/150\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.6792 - accuracy: 0.5858 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 123/150\n",
      "19/19 [==============================] - 2s 82ms/step - loss: 0.6792 - accuracy: 0.5825 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 124/150\n",
      "19/19 [==============================] - 2s 85ms/step - loss: 0.6830 - accuracy: 0.5727 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 125/150\n",
      "19/19 [==============================] - 2s 92ms/step - loss: 0.6839 - accuracy: 0.5651 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 126/150\n",
      "19/19 [==============================] - 1s 77ms/step - loss: 0.6863 - accuracy: 0.5604 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 127/150\n",
      "19/19 [==============================] - 1s 77ms/step - loss: 0.6847 - accuracy: 0.5657 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 128/150\n",
      "19/19 [==============================] - 2s 88ms/step - loss: 0.6844 - accuracy: 0.5656 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 129/150\n",
      "19/19 [==============================] - 2s 91ms/step - loss: 0.6829 - accuracy: 0.5755 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 130/150\n",
      "19/19 [==============================] - 1s 78ms/step - loss: 0.6790 - accuracy: 0.5834 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 131/150\n",
      "19/19 [==============================] - 1s 77ms/step - loss: 0.6859 - accuracy: 0.5585 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 132/150\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.6745 - accuracy: 0.5973 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 133/150\n",
      "19/19 [==============================] - 2s 89ms/step - loss: 0.6749 - accuracy: 0.5975 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 134/150\n",
      "19/19 [==============================] - 2s 92ms/step - loss: 0.6868 - accuracy: 0.5547 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 135/150\n",
      "19/19 [==============================] - 1s 78ms/step - loss: 0.6800 - accuracy: 0.5867 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 136/150\n",
      "19/19 [==============================] - 1s 79ms/step - loss: 0.6762 - accuracy: 0.5948 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 137/150\n",
      "19/19 [==============================] - 1s 76ms/step - loss: 0.6869 - accuracy: 0.5582 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 138/150\n",
      "19/19 [==============================] - 2s 83ms/step - loss: 0.6811 - accuracy: 0.5815 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 139/150\n",
      "19/19 [==============================] - 2s 81ms/step - loss: 0.6831 - accuracy: 0.5737 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 140/150\n",
      "19/19 [==============================] - 1s 79ms/step - loss: 0.6822 - accuracy: 0.5750 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 141/150\n",
      "19/19 [==============================] - 1s 79ms/step - loss: 0.6823 - accuracy: 0.5714 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 142/150\n",
      "19/19 [==============================] - 1s 77ms/step - loss: 0.6786 - accuracy: 0.5876 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 143/150\n",
      "19/19 [==============================] - 1s 74ms/step - loss: 0.6798 - accuracy: 0.5823 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 144/150\n",
      "19/19 [==============================] - 2s 84ms/step - loss: 0.6862 - accuracy: 0.5624 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 145/150\n",
      "19/19 [==============================] - 2s 85ms/step - loss: 0.6874 - accuracy: 0.5585 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 146/150\n",
      "19/19 [==============================] - 2s 97ms/step - loss: 0.6852 - accuracy: 0.5631 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 147/150\n",
      "19/19 [==============================] - 2s 95ms/step - loss: 0.6748 - accuracy: 0.6005 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 148/150\n",
      "19/19 [==============================] - 2s 79ms/step - loss: 0.6784 - accuracy: 0.5909 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 149/150\n",
      "19/19 [==============================] - 2s 82ms/step - loss: 0.6787 - accuracy: 0.5834 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "Epoch 150/150\n",
      "19/19 [==============================] - 1s 75ms/step - loss: 0.6880 - accuracy: 0.5561 - val_loss: 0.6818 - val_accuracy: 0.5759\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6811 - accuracy: 0.5778\n",
      "score on test: 0.5777778029441833\n",
      "[[ 0 19]\n",
      " [ 0 26]]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'score'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_40067/2453478933.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mtest_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtest_score\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmax_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'score'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.layers import Dropout\n",
    "# split an additional validation dataset\n",
    "\n",
    "nn = True\n",
    "\n",
    "if nn:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.05)\n",
    "    x_partial_train, x_validation, y_partial_train, y_validation = train_test_split(X_train, y_train, test_size=0.3)\n",
    "    model=models.Sequential()\n",
    "    model.add(layers.Dense(4096,activation='relu',input_shape=(14,)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(layers.Dense(2048,activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(layers.Dense(1024,activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(layers.Dense(512,activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(layers.Dense(256,activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(layers.Dense(128,activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(layers.Dense(64,activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(layers.Dense(32,activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(layers.Dense(16,activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(layers.Dense(1,activation='sigmoid'))\n",
    "\n",
    "    sgd = optimizers.SGD(lr=0.01)\n",
    "\n",
    "    model.compile(optimizer=sgd,loss='binary_crossentropy',metrics=['accuracy'])  # rmsprop\n",
    "    \n",
    "    model.fit(x_partial_train,y_partial_train,epochs=150,validation_data=(x_validation,y_validation))\n",
    "    print(\"score on test: \" + str(model.evaluate(X_test,y_test)[1]))\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = [0 if y < 0.5 else 1 for y in y_pred]\n",
    "    \n",
    "    y_test.reset_index(drop=True,inplace=True)\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    test_score = model.score(X_test, y_test)\n",
    "    \n",
    "    if test_score > max_score:\n",
    "        max_score = test_score\n",
    "        max_model = \"Neural Network\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36f777cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Naive Bayes', 0.7111111111111111)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_model_name, max_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "138d72f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"predict_now.sav\"\n",
    "\n",
    "with open(filename,'wb') as f:\n",
    "    pickle.dump(max_model, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
